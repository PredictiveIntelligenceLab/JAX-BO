{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import random, vmap\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from jaxbo.mcmc_models import GP\n",
    "from jaxbo.utils import normalize, compute_w_gmm\n",
    "from jaxbo.test_functions import *\n",
    "\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test function\n",
    "f, p_x, dim, lb, ub = oakley()\n",
    "\n",
    "# Problem settings\n",
    "N = 5\n",
    "noise = 0.0\n",
    "options = {'kernel': 'RBF',\n",
    "           'criterion': 'LW-LCB', \n",
    "           'input_prior': p_x,\n",
    "           'kappa': 2.0,\n",
    "           'nIter': 20}\n",
    "mcmc_settings = {'num_warmup': 500,\n",
    "                 'num_samples': 50,\n",
    "                 'num_chains': 1,\n",
    "                 'target_accept_prob': 0.9}\n",
    "gp_model = GP(options)\n",
    "\n",
    "# Fetch domain bounds\n",
    "bounds = {'lb': lb, 'ub': ub}\n",
    "\n",
    "# Initial training data\n",
    "X = lb + (ub-lb)*lhs(dim, N)\n",
    "y = vmap(f)(X)\n",
    "y = y + noise*y.std(0)*onp.random.normal(y.shape)\n",
    "\n",
    "# Test data\n",
    "if dim == 1:\n",
    "    create_plots = True\n",
    "    nn = 1000\n",
    "    X_star = np.linspace(lb[0], ub[0], nn)[:,None]\n",
    "    y_star = vmap(f)(X_star)\n",
    "elif dim == 2:\n",
    "    create_plots = True\n",
    "    nn = 80\n",
    "    xx = np.linspace(lb[0], ub[0], nn)\n",
    "    yy = np.linspace(lb[1], ub[1], nn)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    X_star = np.concatenate([XX.flatten()[:,None], \n",
    "                             YY.flatten()[:,None]], axis = 1)\n",
    "    y_star = vmap(f)(X_star)\n",
    "else:\n",
    "    create_plots = False\n",
    "    nn = 20000\n",
    "    X_star = lb + (ub-lb)*lhs(dim, nn)\n",
    "    y_star = vmap(f)(X_star)\n",
    "\n",
    "# True location of global minimum\n",
    "idx_true = np.argmin(y_star)\n",
    "true_x = X_star[idx_true,:]\n",
    "true_y = y_star.min()\n",
    "dom_bounds = tuple(map(tuple, np.vstack((lb, ub)).T))\n",
    "result = minimize(f, true_x, jac=None, method='L-BFGS-B', bounds = dom_bounds)\n",
    "true_x, true_y = result.x, result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train GP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 550/550 [00:04<00:00, 115.17it/s, 31 steps of size 1.16e-01. acc. prob=0.84]\n"
     ]
    }
   ],
   "source": [
    "rng_key = random.PRNGKey(0)\n",
    "norm_batch, norm_const = normalize(X, y)\n",
    "print('Train GP...')\n",
    "key1, key2 = random.split(rng_key)\n",
    "samples = gp_model.train(norm_batch,\n",
    "                         key1,\n",
    "                         mcmc_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_keys = random.split(key2, \n",
    "                        mcmc_settings['num_samples'] * mcmc_settings['num_chains'])\n",
    "kwargs = {'samples': samples,\n",
    "          'batch': norm_batch,\n",
    "          'norm_const': norm_const,\n",
    "          'bounds': bounds,\n",
    "          'rng_keys': rng_keys}\n",
    "# Test accuracy\n",
    "mean, std = gp_model.predict(X_star, **kwargs)\n",
    "lower = mean - 2.0*std\n",
    "upper = mean + 2.0*std\n",
    "# Check accuracy\n",
    "error = np.linalg.norm(mean-y_star,2)/np.linalg.norm(y_star,2)\n",
    "print(\"Relative L2 error u: %e\" % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "------------------------- Iteration 1/20 -------------------------\n",
      "-------------------------------------------------------------------\n",
      "Train GP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 550/550 [00:04<00:00, 123.14it/s, 31 steps of size 1.16e-01. acc. prob=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit GMM...\n"
     ]
    }
   ],
   "source": [
    "# Main Bayesian optimization loop\n",
    "rng_key = random.PRNGKey(0)\n",
    "for it in range(options['nIter']):\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------------- Iteration %d/%d -------------------------' % (it+1, options['nIter']))\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    # Fetch normalized training data\n",
    "    norm_batch, norm_const = normalize(X, y)\n",
    "\n",
    "    # Train GP model\n",
    "    print('Train GP...')\n",
    "    key1, key2 = random.split(rng_key)\n",
    "    samples = gp_model.train(norm_batch,\n",
    "                             key1,\n",
    "                             mcmc_settings)\n",
    "    # For now just take the average of the sample (later implement posterior inference)\n",
    "    rng_keys = random.split(key2, \n",
    "                            mcmc_settings['num_samples'] * mcmc_settings['num_chains'])\n",
    "    \n",
    "    # Fit GMM\n",
    "    if options['criterion'] == 'LW-LCB' or options['criterion'] == 'LW-US':\n",
    "        print('Fit GMM...')\n",
    "        rng_key = random.split(rng_key)[0]\n",
    "        kwargs = {'samples': samples,\n",
    "                  'rng_keys': rng_keys,\n",
    "                  'batch': norm_batch,\n",
    "                  'norm_const': norm_const,\n",
    "                  'bounds': bounds,\n",
    "                  'rng_key': rng_key}\n",
    "        gmm_vars = gp_model.fit_gmm(N_samples = 10000, **kwargs)\n",
    "    else:\n",
    "        gmm_vars = None\n",
    "\n",
    "    # Compute next point via minimizing the acquisition function\n",
    "    print('Computing next acquisition point...')\n",
    "    kwargs = {'samples': samples,\n",
    "                  'rng_keys': rng_keys,\n",
    "                  'batch': norm_batch,\n",
    "                  'norm_const': norm_const,\n",
    "                  'bounds': bounds,\n",
    "                  'rng_key': rng_key,\n",
    "                  'gmm_vars': gmm_vars}\n",
    "    new_X = gp_model.compute_next_point(num_restarts=10, **kwargs)\n",
    "\n",
    "    # Acquire data\n",
    "    new_y = vmap(f)(new_X)\n",
    "    new_y = new_y + noise*new_y.std(0)*onp.random.normal(new_y.shape)\n",
    "\n",
    "    # Augment training data\n",
    "    print('Updating data-set...')\n",
    "    X = np.concatenate([X, new_X], axis = 0)\n",
    "    y = np.concatenate([y, new_y], axis = 0)\n",
    "\n",
    "    # Print current best\n",
    "    idx_best = np.argmin(y)\n",
    "    best_x = X[idx_best,:]\n",
    "    best_y = y.min()\n",
    "    print('True location: (%f,%f), True value: %f' % (true_x[0], true_x[1], true_y))\n",
    "    print('Best location: (%f,%f), Best value: %f' % (best_x[0], best_x[1], best_y))\n",
    "    print('New  location: (%f,%f), New  value: %f' % (new_X[0,0], new_X[0,1], new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "mean, std = gp_model.predict(X_star, **kwargs)\n",
    "lower = mean - 2.0*std\n",
    "upper = mean + 2.0*std\n",
    "# Check accuracy\n",
    "error = np.linalg.norm(mean-y_star,2)/np.linalg.norm(y_star,2)\n",
    "print(\"Relative L2 error u: %e\" % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_plots:\n",
    "    # Compute predictions\n",
    "    if options['criterion'] == 'LW-LCB' or options['criterion'] == 'LW-US':\n",
    "        w_pred = compute_w_gmm(X_star, **kwargs)\n",
    "    else:\n",
    "        w_pred = np.zeros(X_star.shape[0])\n",
    "        \n",
    "    acq_fun = lambda x: gp_model.acquisition(x, **kwargs)\n",
    "    a_pred = vmap(acq_fun)(X_star)\n",
    "    x_new = gp_model.compute_next_point(num_restarts=10, **kwargs)\n",
    "\n",
    "    # Convert to NumPy\n",
    "    X_star = onp.array(X_star)\n",
    "    y_star = onp.array(y_star)\n",
    "    mean = onp.array(mean)\n",
    "    std = onp.array(std)\n",
    "    w_pred = onp.array(w_pred)\n",
    "    a_pred = onp.array(a_pred)\n",
    "    XX = onp.array(XX)\n",
    "    YY = onp.array(YY)\n",
    "    Y_star = griddata(X_star, y_star, (XX, YY), method='cubic')\n",
    "    Y_pred = griddata(X_star, mean, (XX, YY), method='cubic')\n",
    "    Y_std  = griddata(X_star, std, (XX, YY), method='cubic')\n",
    "    W_star = griddata(X_star, w_pred, (XX, YY), method='cubic')\n",
    "    A_star = griddata(X_star, a_pred, (XX, YY), method='cubic')\n",
    "\n",
    "    # Plot\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams['axes.linewidth']=3\n",
    "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "    rc('text', usetex=True)\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    fig = plt.contourf(XX, YY, Y_star)\n",
    "    plt.plot(X[:,0], X[:,1], 'r.', ms = 6, alpha = 0.8)\n",
    "    # plt.plot(true_x[0], true_x[1], 'md', ms = 8, alpha = 1.0)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Exact u(x)')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    fig = plt.contourf(XX, YY, Y_pred)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Predicted mean')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    fig = plt.contourf(XX, YY, 2.0*Y_std)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Two stds')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    fig = plt.contourf(XX, YY, np.abs(Y_star-Y_pred))\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Absolute error')\n",
    "    plt.axis('square')\n",
    "#     plt.savefig('function_prediction.png', dpi = 300)\n",
    "\n",
    "    idx_max = np.argmin(a_pred)\n",
    "    plt.figure(figsize = (12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = plt.contourf(XX, YY, W_star)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'$w_{GMM}(x)$')\n",
    "    plt.axis('square')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fig = plt.contourf(XX, YY, A_star)\n",
    "    plt.colorbar(fig)\n",
    "    # plt.plot(x0[:,0], x0[:,1], 'ms')\n",
    "    # plt.plot(X_star[idx_max,0], X_star[idx_max,1], 'md')\n",
    "    plt.plot(x_new[:,0], x_new[:,1], 'md', label = 'new X')\n",
    "    plt.legend(frameon = False)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'%s(x)' % (options['criterion']))\n",
    "    plt.axis('square')\n",
    "#     plt.savefig('acquisition.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
