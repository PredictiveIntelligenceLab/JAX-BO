{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import random, vmap\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from jaxbo.models import HeterogeneousMultifidelityGP\n",
    "from jaxbo.utils import normalize_HeterogeneousMultifidelityGP, compute_w_gmm\n",
    "from jaxbo.test_functions import *\n",
    "\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test function\n",
    "f, p_x, dim, lb, ub = multifidelity_branin()\n",
    "f_L, f_H = f\n",
    "\n",
    "# Fetch domain bounds\n",
    "bounds = {'lb': lb, 'ub': ub}\n",
    "\n",
    "# Problem setttings\n",
    "NL = 100\n",
    "NH = 5\n",
    "noiseL = 0.0\n",
    "noiseH = 0.0\n",
    "options = {'kernel': 'RBF',\n",
    "           'criterion': 'LW-LCB', \n",
    "           'input_prior': p_x,\n",
    "           'kappa': 2.0,\n",
    "           'nIter': 20}\n",
    "layers = [1, 10, 2]\n",
    "gp_model = HeterogeneousMultifidelityGP(options, layers)\n",
    "\n",
    "# Initial training data\n",
    "XL = lb + (ub-lb)*lhs(dim, NL)\n",
    "yL = vmap(f_L)(XL)\n",
    "yL = yL + noiseL*yL.std(0)*onp.random.normal(yL.shape)\n",
    "\n",
    "XH = lb + (ub-lb)*lhs(dim, NH)\n",
    "yH = vmap(f_H)(XH)\n",
    "yH = yH + noiseH*yH.std(0)*onp.random.normal(yH.shape)\n",
    "\n",
    "y = np.concatenate([yL, yH])\n",
    "\n",
    "# Test data\n",
    "if dim == 1:\n",
    "    create_plots = True\n",
    "    nn = 1000\n",
    "    X_star = np.linspace(lb[0], ub[0], nn)[:,None]\n",
    "    yL_star = vmap(f_L)(X_star)\n",
    "    yH_star = vmap(f_H)(X_star)\n",
    "elif dim == 2:\n",
    "    create_plots = True\n",
    "    nn = 80\n",
    "    xx = np.linspace(lb[0], ub[0], nn)\n",
    "    yy = np.linspace(lb[1], ub[1], nn)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    X_star = np.concatenate([XX.flatten()[:,None], \n",
    "                             YY.flatten()[:,None]], axis = 1)\n",
    "    yL_star = vmap(f_L)(X_star)\n",
    "    yH_star = vmap(f_H)(X_star)\n",
    "else:\n",
    "    create_plots = False\n",
    "    nn = 20000\n",
    "    X_star = lb + (ub-lb)*lhs(dim, nn)\n",
    "    yL_star = vmap(f_L)(X_star)\n",
    "    yH_star = vmap(f_H)(X_star)\n",
    "\n",
    "# True location of global minimum\n",
    "idx_true = np.argmin(yH_star)\n",
    "true_x = X_star[idx_true,:]\n",
    "true_y = yH_star.min()\n",
    "dom_bounds = tuple(map(tuple, np.vstack((lb, ub)).T))\n",
    "result = minimize(f_H, true_x, jac=None, method='L-BFGS-B', bounds = dom_bounds)\n",
    "true_x, true_y = result.x, result.fun\n",
    "\n",
    "# Deliberately remove last dimension from low fidelity input data\n",
    "XL = XL[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "------------------------- Iteration 1/20 -------------------------\n",
      "-------------------------------------------------------------------\n",
      "Train GP...\n"
     ]
    }
   ],
   "source": [
    "# Main Bayesian optimization loop\n",
    "rng_key = random.PRNGKey(0)\n",
    "for it in range(options['nIter']):\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------------- Iteration %d/%d -------------------------' % (it+1, options['nIter']))\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    # Fetch normalized training data\n",
    "    norm_batch, norm_const = normalize_HeterogeneousMultifidelityGP(XL, yL, XH, yH, bounds)\n",
    "\n",
    "    # Train GP model\n",
    "    print('Train GP...')\n",
    "    rng_key = random.split(rng_key)[0]\n",
    "    opt_params = gp_model.train(norm_batch,\n",
    "                                rng_key,\n",
    "                                num_restarts = 10)\n",
    "\n",
    "    # Fit GMM\n",
    "    if options['criterion'] == 'LW-LCB' or options['criterion'] == 'LW-US':\n",
    "        print('Fit GMM...')\n",
    "        rng_key = random.split(rng_key)[0]\n",
    "        kwargs = {'params': opt_params,\n",
    "                  'batch': norm_batch,\n",
    "                  'norm_const': norm_const,\n",
    "                  'bounds': bounds,\n",
    "                  'rng_key': rng_key}\n",
    "        gmm_vars = gp_model.fit_gmm(**kwargs, N_samples = 10000)\n",
    "    else:\n",
    "        gmm_vars = None\n",
    "\n",
    "    # Compute next point via minimizing the acquisition function\n",
    "    print('Computing next acquisition point...')\n",
    "    kwargs = {'params': opt_params,\n",
    "              'batch': norm_batch,\n",
    "              'norm_const': norm_const,\n",
    "              'bounds': bounds,\n",
    "              'gmm_vars': gmm_vars}\n",
    "    new_X = gp_model.compute_next_point(num_restarts=10, **kwargs)\n",
    "\n",
    "    # Acquire data\n",
    "    new_y = vmap(f_H)(new_X)\n",
    "    new_y = new_y + noiseH*new_y.std(0)*onp.random.normal(new_y.shape)\n",
    "\n",
    "    # Augment training data\n",
    "    print('Updating data-set...')\n",
    "    XH = np.concatenate([XH, new_X], axis = 0)\n",
    "    yH = np.concatenate([yH, new_y], axis = 0)\n",
    "\n",
    "    # Print current best\n",
    "    idx_best = np.argmin(yH)\n",
    "    best_x = XH[idx_best,:]\n",
    "    best_y = yH.min()\n",
    "    print('True location: ({}), True value: {}'.format(true_x, true_y))\n",
    "    print('Best location: ({}), Best value: {}'.format(best_x, best_y))\n",
    "    print('New  location: ({}), New  value: {}'.format(new_X, new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "mean, std = gp_model.predict(X_star, **kwargs)\n",
    "lower = mean - 2.0*std\n",
    "upper = mean + 2.0*std\n",
    "# Check accuracy\n",
    "error = np.linalg.norm(mean-yH_star,2)/np.linalg.norm(yH_star,2)\n",
    "print(\"Relative L2 error u: %e\" % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = opt_params[gp_model.nn_params_ids]\n",
    "XL_pred = gp_model.net_apply(gp_model.unravel(nn_params), X_star[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lb)\n",
    "print(ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(XL_pred[:,0], XL_pred[:,1], '.')\n",
    "# plt.plot(X_star[:,0], X_star[:,1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLs = f_L(XL_pred)\n",
    "yHs = f_H(XL_pred)\n",
    "# plt.plot(yH_star, yH_star, 'k--')\n",
    "# plt.plot(yL_star, yH_star, '.')\n",
    "plt.plot(yLs, yHs, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_plots:\n",
    "    # Compute predictions\n",
    "    if options['criterion'] == 'LW-LCB' or options['criterion'] == 'LW-US':\n",
    "        w_pred = compute_w_gmm(X_star, **kwargs)\n",
    "    else:\n",
    "        w_pred = np.zeros(X_star.shape[0])\n",
    "        \n",
    "    acq_fun = lambda x: gp_model.acquisition(x, **kwargs)\n",
    "    a_pred = vmap(acq_fun)(X_star)\n",
    "    x_new = gp_model.compute_next_point(num_restarts=10, **kwargs)\n",
    "\n",
    "    # Convert to NumPy\n",
    "    X_star = onp.array(X_star)\n",
    "    yH_star = onp.array(yH_star)\n",
    "    mean = onp.array(mean)\n",
    "    std = onp.array(std)\n",
    "    w_pred = onp.array(w_pred)\n",
    "    a_pred = onp.array(a_pred)\n",
    "    XX = onp.array(XX)\n",
    "    YY = onp.array(YY)\n",
    "    Y_star = griddata(X_star, yH_star, (XX, YY), method='cubic')\n",
    "    Y_pred = griddata(X_star, mean, (XX, YY), method='cubic')\n",
    "    Y_std  = griddata(X_star, std, (XX, YY), method='cubic')\n",
    "    W_star = griddata(X_star, w_pred, (XX, YY), method='cubic')\n",
    "    A_star = griddata(X_star, a_pred, (XX, YY), method='cubic')\n",
    "\n",
    "    # Plot\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams['axes.linewidth']=3\n",
    "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "    rc('text', usetex=True)\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    fig = plt.contourf(XX, YY, Y_star)\n",
    "    plt.plot(XH[:,0], XH[:,1], 'r.', ms = 6, alpha = 0.8)\n",
    "    # plt.plot(true_x[0], true_x[1], 'md', ms = 8, alpha = 1.0)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Exact u(x)')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    fig = plt.contourf(XX, YY, Y_pred)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Predicted mean')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    fig = plt.contourf(XX, YY, 2.0*Y_std)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Two stds')\n",
    "    plt.axis('square')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    fig = plt.contourf(XX, YY, np.abs(Y_star-Y_pred))\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'Absolute error')\n",
    "    plt.axis('square')\n",
    "#     plt.savefig('function_prediction.png', dpi = 300)\n",
    "\n",
    "    idx_max = np.argmin(a_pred)\n",
    "    plt.figure(figsize = (12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = plt.contourf(XX, YY, W_star)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'$w_{GMM}(x)$')\n",
    "    plt.axis('square')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fig = plt.contourf(XX, YY, A_star)\n",
    "    plt.colorbar(fig)\n",
    "    # plt.plot(x0[:,0], x0[:,1], 'ms')\n",
    "    # plt.plot(X_star[idx_max,0], X_star[idx_max,1], 'md')\n",
    "    plt.plot(x_new[:,0], x_new[:,1], 'md', label = 'new X')\n",
    "    plt.legend(frameon = False)\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.title(r'%s(x)' % (options['criterion']))\n",
    "    plt.axis('square')\n",
    "#     plt.savefig('acquisition.png', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
